@misc{kapelyukhDALLEBotIntroducingWebScale2022,
 abstract = {We introduce the first work to explore web-scale diffusion models for robotics. DALL-E-Bot enables a robot to rearrange objects in a scene, by first inferring a text description of those objects, then generating an image representing a natural, human-like arrangement of those objects, and finally physically arranging the objects according to that image. The significance is that we achieve this zero-shot using DALLE, without needing any further data collection or training. Encouraging real-world results with human studies show that this is an exciting direction for the future of web-scale robot learning algorithms. We also propose a list of recommendations to the text-to-image community, to align further developments of these models with applications to robotics. Videos are available at: https://www.robot-learning.uk/dall-e-bot.},
 archiveprefix = {arXiv},
 author = {Kapelyukh, Ivan and Vosylius, Vitalis and Johns, Edward},
 date = {2022-10-05},
 eprint = {2210.02438},
 eprinttype = {arxiv},
 file = {C\:\\Users\e̊d0orange\\Documents\\Zotero\\storage\\55K4A7W5\\Kapelyukh 等。 - 2022 - DALL-E-Bot Introducing Web-Scale Diffusion Models.pdf},
 keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
 langid = {english},
 number = {arXiv:2210.02438},
 primaryclass = {cs},
 publisher = {arXiv},
 shorttitle = {DALL-E-Bot},
 title = {DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics},
 url = {http://arxiv.org/abs/2210.02438},
 urldate = {2022-10-11}
}

