---
title: Simultaneous Localization And Mapping (SLAM)
summary: SLAM is a technique for obtaining the 3D structure of an unknown environment and sensor motion in the environment. This technique was originally proposed to achieve autonomous control of robots in robotics. The SLAM-based applications have widely become broadened such as computer vision-based online 3D modeling, augmented reality (AR) / virtual reality (VR), and unmanned autonomous vehicles (UAV). Camera and LiDAR are the two main exteroceptive sensors used in SLAM for map modeling, which divided SLAM into two main subsets named Visual SLAM (V-SLAM) and LiDAR-based SLAM. Recently, deep learning has promoted the development of computer vision. The combination of deep learning and SLAM has attracted more and more attention. With the help of target detection, semantic segmentation, and high-level environmental information, SLAM can enable robots to better understand ego motion and the surrounding environment.
# subtitle: Chao Tang, Jingwen Yu, Weinan Chen, Bingyi Xia and Hong Zhang (a joint
#   work between SUSTech and HKUST)
weight: 1
date: 2022-06-18T07:10:14.697Z
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
---