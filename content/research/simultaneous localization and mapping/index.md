---
title: Simultaneous Localization And Mapping (SLAM)
weight: 1
date: 2022-06-18T07:10:14.697Z
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
---
**Introduction**: SLAM is a technique for obtaining the 3D structure of an unknown environment and sensor motion in the environment. This technique was originally proposed to achieve autonomous control of robots in robotics. The SLAM-based applications have widely become broadened such as computer vision-based online 3D modeling, augmented reality (AR) / virtual reality (VR), and unmanned autonomous vehicles (UAV). Camera and LiDAR are the two main exteroceptive sensors used in SLAM for map modeling, which divided SLAM into two main subsets named Visual SLAM (V-SLAM) and LiDAR-based SLAM. Recently, deep learning has promoted the development of computer vision. The combination of deep learning and SLAM has attracted more and more attention. With the help of target detection, semantic segmentation, and high-level environmental information, SLAM can enable robots to better understand ego motion and the surrounding environment.

**Details**: [multi-sensor fusion SLAM](/authors/jingwen_yu)**,** [dense tracking and mapping system](/authors/mingzhe_lv)**,** [visual localization](/authors/bingxi_liu)**,** [point cloud place recognition](/authors/zhilong_tang)**,** [dense mapping](/authors/guangcheng_chen)**,** [performance evaluation of robot localization with batural landmarks](/authors/yaling_pan)**,** [visual localization](/authors/jiahao_ruan)**,** [LiDAR place recognition](/authors/ruihao_zhou)**,** [active view planning for feature and optimization-based visual SLAM](/authors/changfei_fu)**,** [long-term SLAM](/authors/jiamin_zheng)**,** [point cloud registration](/authors/wen_li)**,** [navigation with scene graph prediction](/authors/zijun_lin)**,** [3D LiDAR mapping and stable navigation of designated routes](/authors/renxiang_xiao)