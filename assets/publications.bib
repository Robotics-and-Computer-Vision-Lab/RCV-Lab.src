
@inproceedings{chen_keyframe_2022,
	title = {Keyframe {Selection} with {Information} {Occupancy} {Grid} {Model} for {Long}-term {Data} {Association}},
	abstract = {As the basic of visual tracking and mapping in VSLAM systems, keyframe selection plays an essential role. In previous works, keyframes are selected according to a series of view change-based judgement that aim to provide the referenced tracking markers and enhance the current visual tracking. However, the enrichment of environment information is always ignored, which results to the lacking of complete environment representation, and the failure of closed-loop detection or submap alignment. In this paper, we propose a keyframe selection judgement based on the deep image global descriptor and information enrichment. The image is expressed by an illumination invariant descriptor for an appropriate statical abstraction; an information enrichment judgement is proposed based on the deep descriptor, by which the environment representation can be completed. The experimental results are conducted showing the advantage of our method in terms of image representation and information enrichment. The proposed information-based keyframe selection judgement can raise the tracking precision and the loop-closed detection rate.},
	booktitle = {2022 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Chen, Weinan and Ye, Hanjing and Zhu, Lei and Tang, Chao and Fu, Changfei and Chen, Yonggang and Zhang, Hong},
	year = {2022},
}

@article{chen_robustness_2021,
	title = {Robustness {Improvement} of {Using} {Pre}-{Trained} {Network} in {Visual} {Odometry} for {On}-{Road} {Driving}},
	volume = {70},
	issn = {0018-9545, 1939-9359},
	url = {https://ieeexplore.ieee.org/document/9573476/},
	doi = {10.1109/TVT.2021.3120214},
	abstract = {Robustness in on-road driving Visual Odometry (VO) systems is critical, as it determines the reliable performance in various scenarios and environments. Especially with the development of data-driven technology, the combination of data-driven VO and model-based VO has achieved accurate tracking performance. However, the lack of generalization of pre-trained deep neural networks (DNN) limits the robustness of such a combination in unseen environments. In this study, we introduce a novel framework with appropriate usage of DNN prediction and improve the robustness in the self-driving application. Based on the characteristic of on-road self-driving motion and the DNN output, we propose a two-step optimization strategy with a variable degree of freedom (DoF), i.e., the use of two types of DoF representations during pose estimation. Speciﬁcally, our two-step optimization operates according to the residual of the optimization with the motion label classiﬁcation from the pre-trained DNN, as well as our proposed Motion Evaluation by essential matrix construction. Experimental results show that our framework obtains better tracking accuracy than the existing methods.},
	language = {en},
	number = {12},
	urldate = {2022-12-08},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Chen, Weinan and Zhu, Lei and Loo, Shing Yan and Wang, Jiankun and Wang, Chaoqun and Meng, Max Q.-H. and Zhang, Hong},
	month = dec,
	year = {2021},
	pages = {12415--12426},
	file = {Chen 等 - 2021 - Robustness Improvement of Using Pre-Trained Networ.pdf:/home/red0orange/Zotero/storage/4RS9CTWH/Chen 等 - 2021 - Robustness Improvement of Using Pre-Trained Networ.pdf:application/pdf},
}

@article{chen_dynamic_2022,
	title = {Dynamic {Strategy} of {Keyframe} {Selection} {With} {PD} {Controller} for {VSLAM} {Systems}},
	volume = {27},
	issn = {1083-4435, 1941-014X},
	url = {https://ieeexplore.ieee.org/document/9352537/},
	doi = {10.1109/TMECH.2021.3058617},
	abstract = {Keyframe (KF) selection in a KF-based visual simultaneous localization and mapping (VSLAM) system is critical. In previous studies, static thresholds have been used for KF selection decision making; however, suboptimal performance can result from the use of such thresholds. To obtain a better KF setting than that obtained with the existing methods, in this article, we introduce a dynamic KF selection strategy. By considering both the view change between camera observation and KFs in the built map and the rate of this change, we propose to dynamically adjust the threshold for KF selection. A proportion and derivative (PD) controller is designed with the feedback of estimated view change, where the PD controller output is used for KF selection. According to the experimental results, compared with the existing studies, our method can improve the precision of visual tracking by 17.5\% and 16.7\% based on two popular VSLAM systems.},
	language = {en},
	number = {1},
	urldate = {2022-12-08},
	journal = {IEEE/ASME Transactions on Mechatronics},
	author = {Chen, Weinan and Zhu, Lei and Lin, Xubin and He, Li and Guan, Yisheng and Zhang, Hong},
	month = feb,
	year = {2022},
	pages = {115--125},
	file = {Chen 等 - 2022 - Dynamic Strategy of Keyframe Selection With PD Con.pdf:/home/red0orange/Zotero/storage/MS73WLCR/Chen 等 - 2022 - Dynamic Strategy of Keyframe Selection With PD Con.pdf:application/pdf},
}

@article{chen_ceb-map_2021,
	title = {{CEB}-{Map}: {Visual} {Localization} {Error} {Prediction} for {Safe} {Navigation}},
	volume = {21},
	issn = {1530-437X, 1558-1748, 2379-9153},
	shorttitle = {{CEB}-{Map}},
	url = {https://ieeexplore.ieee.org/document/9109263/},
	doi = {10.1109/JSEN.2020.2999641},
	abstract = {For safe visual navigation, areas with high localization errors should be concentrated and could be further reﬁned by additional mapping operations. Given an environment map, we propose to predict the visual localization error and hence to either improve the navigation performance or call an additional mapping to reﬁne the built map. Previous work adopts the uncertainty of landmarks for the error prediction. In our work, we take into account both the spatial distribution of visual landmarks and the uncertainty of landmarks. Our main idea is that standing at one place, a good spatial distribution of landmarks means a sufﬁcient enough visible landmarks from all views at that place, i.e., enough landmarks under arbitrary view-direction. Combining the spatial distribution and the uncertainty of landmarks, we propose a new framework to predict the error of visual localization. Furthermore, we show that additional mapping in the area with high predicted error can signiﬁcantly improve the visual localization precision. Experimental results show that there is a strong relationship between the predicted error and the real error, of which the absolute value of correlation coefﬁcient is between 0.707 to 0.915. We apply our method to conduct an optimal reﬁning policy on the built map and the experimental results show the improved localization precision. Applications on navigation test verify the superiority of our proposed method.},
	language = {en},
	number = {10},
	urldate = {2022-12-08},
	journal = {IEEE Sensors Journal},
	author = {Chen, Weinan and Zhu, Lei and Wang, Chaoqun and He, Li and Meng, Max Q.-H.},
	month = may,
	year = {2021},
	pages = {11769--11780},
	file = {Chen 等 - 2021 - CEB-Map Visual Localization Error Prediction for .pdf:/home/red0orange/Zotero/storage/999EDSQI/Chen 等 - 2021 - CEB-Map Visual Localization Error Prediction for .pdf:application/pdf},
}

@article{lin_robust_2022,
	title = {Robust {Data} {Association} against {Detection} {Deficiency} for {Semantic} {SLAM}},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Lin, Xubin and Ruan, Jiahao and Yang, Yirui and He, Li and Guan, Yisheng and Zhang, Hong},
	year = {2022},
}

@article{an_deep_2022,
	title = {Deep {Tri}-{Training} for {Semi}-{Supervised} {Image} {Segmentation}},
	volume = {7},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {An, Shan and Zhu, Haogang and Zhang, Jiaao and Ye, Junjie and Wang, Siliang and Yin, Jianqin and Zhang, Hong},
	year = {2022},
	note = {Publisher: IEEE},
	pages = {10097--10104},
}

@article{yang_robust_2022,
	title = {Robust {UWB} {Indoor} {Localization} for {NLOS} {Scenes} via {Learning} {Spatial}-{Temporal} {Features}},
	volume = {22},
	number = {8},
	journal = {IEEE Sensors Journal},
	author = {Yang, Bo and Li, Jun and Shao, Zhanpeng and Zhang, Hong},
	year = {2022},
	note = {Publisher: IEEE},
	pages = {7990--8000},
}

@article{wang_real-time_2020,
	title = {Real-time 3-{D} semantic scene parsing with {LiDAR} sensors},
	journal = {IEEE Transactions on Cybernetics},
	author = {Wang, Fei and Zhuang, Yan and Zhang, Hong and Gu, Hong},
	year = {2020},
	note = {Publisher: IEEE},
}

@article{shao_learning_2020,
	title = {Learning representations from skeletal self-similarities for cross-view action recognition},
	volume = {31},
	number = {1},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Shao, Zhanpeng and Li, Youfu and Zhang, Hong},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {160--174},
}

@article{fu_fastorb-slam_2021,
	title = {{FastORB}-{SLAM}: {A} fast {ORB}-{SLAM} method with {Coarse}-to-{Fine} descriptor independent keypoint matching},
	journal = {IEEE Transactions on Image Processing},
	author = {Fu, Q and Yu, H and Wang, X and Yang, Z and Zhang, H and Mian, A},
	year = {2021},
}

@article{yang_resilient_2021,
	title = {Resilient indoor localization system based on {UWB} and visual–inertial sensors for complex environments},
	volume = {70},
	journal = {IEEE Transactions on Instrumentation and Measurement},
	author = {Yang, Bo and Li, Jun and Zhang, Hong},
	year = {2021},
	note = {Publisher: IEEE},
	pages = {1--14},
}

@article{shakeri_polarimetric_2021,
	title = {Polarimetric monocular dense mapping using relative deep depth prior},
	volume = {6},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Shakeri, Moein and Loo, Shing Yang and Zhang, Hong and Hu, Kangkang},
	year = {2021},
	note = {Publisher: IEEE},
	pages = {4512--4519},
}

@article{wen_dense_2021,
	title = {Dense point cloud map construction based on stereo {VINS} for mobile vehicles},
	volume = {178},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Wen, Shuhuan and Liu, Xin and Zhang, Hong and Sun, Fuchun and Sheng, Miao and Fan, Shaokang},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {328--344},
}

@article{wen_semantic_2021,
	title = {Semantic visual {SLAM} in dynamic environment},
	volume = {45},
	number = {4},
	journal = {Autonomous Robots},
	author = {Wen, Shuhuan and Li, Pengjiang and Zhao, Yongjie and Zhang, Hong and Sun, Fuchun and Wang, Zhe},
	year = {2021},
	note = {Publisher: Springer},
	pages = {493--504},
}

@inproceedings{chen_perspective_2022,
	title = {Perspective {Phase} {Angle} {Model} for {Polarimetric} {3D} {Reconstruction}},
	booktitle = {European {Conference} on {Computer} {Vision}},
	publisher = {Springer},
	author = {Chen, Guangcheng and He, Li and Guan, Yisheng and Zhang, Hong},
	year = {2022},
	pages = {398--414},
}

@inproceedings{elkerdawy_fire_2022,
	title = {Fire {Together} {Wire} {Together}: {A} {Dynamic} {Pruning} {Approach} with {Self}-{Supervised} {Mask} {Prediction}},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Elkerdawy, Sara and Elhoushi, Mostafa and Zhang, Hong and Ray, Nilanjan},
	year = {2022},
	pages = {12454--12463},
}

@inproceedings{loo_deeprelativefusion_2021,
	title = {Deeprelativefusion: {Dense} monocular slam using single-image relative depth prediction},
	booktitle = {2021 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Loo, Shing Yan and Mashohor, Syamsiah and Tang, Sai Hong and Zhang, Hong},
	year = {2021},
	pages = {6641--6648},
}

@inproceedings{yang_uvip_2021,
	title = {{UVIP}: {Robust} {UWB} aided visual-inertial positioning system for complex indoor environments},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Yang, Bo and Li, Jun and Zhang, Hong},
	year = {2021},
	pages = {5454--5460},
}

@inproceedings{lin_robust_2021,
	title = {Robust {Improvement} in {3D} {Object} {Landmark} {Inference} for {Semantic} {Mapping}},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Lin, Xubin and Yang, Yirui and He, Li and Chen, Weinan and Guan, Yisheng and Zhang, Hong},
	year = {2021},
	pages = {13011--13017},
}

@inproceedings{ting_deep_2021,
	title = {Deep snapshot {HDR} reconstruction based on the polarization camera},
	booktitle = {2021 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Ting, Juiwen and Wu, Xuesong and Hu, Kangkang and Zhang, Hong},
	year = {2021},
	pages = {1769--1773},
}

@inproceedings{zhou_ndd_2022,
	title = {{NDD}: {A} {3D} {Point} {Cloud} {Descriptor} {Based} on {Normal} {Distribution} for {Loop} {Closure} {Detection}},
	booktitle = {2022 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Zhou, Ruihao and He, Li and Zhang, Hong and Lin, Xubin and Guan, Yisheng},
	year = {2022},
}

@inproceedings{lv_semantically_2021,
	title = {Semantically {Guided} {Multi}-{View} {Stereo} for {Dense} {3D} {Road} {Mapping}},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Lv, Mingzhe and Tu, Diantao and Tang, Xincheng and Liu, Yuqian and Shen, Shuhan},
	year = {2021},
	pages = {11189--11195},
}
